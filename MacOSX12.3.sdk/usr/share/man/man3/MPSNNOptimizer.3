.TH "MPSNNOptimizer" 3 "Mon Jul 9 2018" "Version MetalPerformanceShaders-119.3" "MetalPerformanceShaders.framework" \" -*- nroff -*-
.ad l
.nh
.SH NAME
MPSNNOptimizer
.SH SYNOPSIS
.br
.PP
.PP
\fC#import <MPSNNOptimizers\&.h>\fP
.PP
Inherits \fBMPSKernel\fP\&.
.PP
Inherited by \fBMPSNNOptimizerAdam\fP, \fBMPSNNOptimizerRMSProp\fP, and \fBMPSNNOptimizerStochasticGradientDescent\fP\&.
.SS "Instance Methods"

.in +1c
.ti -1c
.RI "(nonnull instancetype) \- \fBinitWithDevice:\fP"
.br
.ti -1c
.RI "(void) \- \fBsetLearningRate:\fP"
.br
.in -1c
.SS "Properties"

.in +1c
.ti -1c
.RI "float \fBlearningRate\fP"
.br
.ti -1c
.RI "float \fBgradientRescale\fP"
.br
.ti -1c
.RI "BOOL \fBapplyGradientClipping\fP"
.br
.ti -1c
.RI "float \fBgradientClipMax\fP"
.br
.ti -1c
.RI "float \fBgradientClipMin\fP"
.br
.ti -1c
.RI "float \fBregularizationScale\fP"
.br
.ti -1c
.RI "\fBMPSNNRegularizationType\fP \fBregularizationType\fP"
.br
.in -1c
.SS "Additional Inherited Members"
.SH "Detailed Description"
.PP 
The \fBMPSNNOptimizer\fP base class, use one of the child classes, not to be directly used\&. Optimizers are generally used to update trainable neural network parameters\&. Users are usually expected to call these MPSKernels from the update methods on their Convolution or BatchNormalization data sources\&.
.PP
Before the gradient is used to update the original value, some preprocessing occurs on each gradient where it is scaled or clipped If regularization is chosen the appropriate regularization loss gradient is added to the value gradient\&. 
.SH "Method Documentation"
.PP 
.SS "\- (nonnull instancetype) initWithDevice: (nonnull id< MTLDevice >) device"
Standard init with default properties per filter type 
.PP
\fBParameters:\fP
.RS 4
\fIdevice\fP The device that the filter will be used on\&. May not be NULL\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
a pointer to the newly initialized object\&. This will fail, returning nil if the device is not supported\&. Devices must be MTLFeatureSet_iOS_GPUFamily2_v1 or later\&. 
.RE
.PP

.PP
Reimplemented from \fBMPSKernel\fP\&.
.PP
Reimplemented in \fBMPSNNOptimizerAdam\fP, \fBMPSNNOptimizerRMSProp\fP, and \fBMPSNNOptimizerStochasticGradientDescent\fP\&.
.SS "\- (void) setLearningRate: (float) newLearningRate"

.SH "Property Documentation"
.PP 
.SS "\- applyGradientClipping\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
\fBA\fP bool which decides if gradient will be clipped  The default value is NO 
.SS "\- gradientClipMax\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The maximum value at which incoming gradient will be clipped before rescaling, applyGradientClipping must be true 
.SS "\- gradientClipMin\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The minimum value at which incoming gradient will be clipped before rescaling, applyGradientClipping must be true 
.SS "\- gradientRescale\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The gradientRescale at which we apply to incoming gradient values  The default value is 1\&.0 
.SS "\- learningRate\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The learningRate at which we update values  The default value is 1e-3 
.SS "\- regularizationScale\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The regularizationScale at which we apply L1 or L2 regularization, it gets ignored if regularization is None  The default value is 0\&.0 
.SS "\- regularizationType\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The regularizationType which we apply\&.  The default value is MPSRegularizationTypeNone 

.SH "Author"
.PP 
Generated automatically by Doxygen for MetalPerformanceShaders\&.framework from the source code\&.
