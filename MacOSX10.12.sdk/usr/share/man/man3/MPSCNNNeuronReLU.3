.TH "MPSCNNNeuronReLU" 3 "Wed Jul 20 2016" "Version MetalPerformanceShaders-60" "MetalPerformanceShaders.framework" \" -*- nroff -*-
.ad l
.nh
.SH NAME
MPSCNNNeuronReLU \- 
.SH SYNOPSIS
.br
.PP
.PP
\fC#import <MPSCNN\&.h>\fP
.PP
Inherits \fBMPSCNNNeuron\fP\&.
.SS "Instance Methods"

.in +1c
.ti -1c
.RI "(nonnull instancetype) \- \fBinitWithDevice:a:\fP"
.br
.ti -1c
.RI "(nonnull instancetype) \- \fBinitWithDevice:\fP"
.br
.in -1c
.SS "Properties"

.in +1c
.ti -1c
.RI "float \fBa\fP"
.br
.in -1c
.SS "Additional Inherited Members"
.SH "Detailed Description"
.PP 
This depends on Metal\&.framework  Specifies the ReLU neuron filter\&. For each pixel, applies the following function: f(x) = x, if x >= 0 = a * x if x < 0 This is called Leaky ReLU in literature\&. Some literature defines classical ReLU as max(0, x)\&. If you want this behavior, simply pass a = 0 
.SH "Method Documentation"
.PP 
.SS "\- (nonnull instancetype) initWithDevice: (nonnull id< MTLDevice >) NS_DESIGNATED_INITIALIZER"
Standard init with default properties per filter type 
.PP
\fBParameters:\fP
.RS 4
\fIdevice\fP The device that the filter will be used on\&. May not be NULL\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
a pointer to the newly initialized object\&. This will fail, returning nil if the device is not supported\&. Devices must be MTLFeatureSet_iOS_GPUFamily2_v1 or later\&. 
.RE
.PP

.PP
Reimplemented from \fBMPSKernel\fP\&.
.SS "\- (nonnull instancetype) \fBinitWithDevice:\fP (nonnull id< MTLDevice >) device(float) NS_DESIGNATED_INITIALIZER"
Initialize the ReLU neuron filter 
.PP
\fBParameters:\fP
.RS 4
\fIdevice\fP The device the filter will run on 
.br
\fIa\fP Filter property 'a'\&. See class discussion\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
A valid \fBMPSCNNNeuronReLU\fP object or nil, if failure\&. 
.RE
.PP


.SH "Author"
.PP 
Generated automatically by Doxygen for MetalPerformanceShaders\&.framework from the source code\&.
