.TH "MPSCNNConvolutionTranspose" 3 "Mon Jul 9 2018" "Version MetalPerformanceShaders-119.3" "MetalPerformanceShaders.framework" \" -*- nroff -*-
.ad l
.nh
.SH NAME
MPSCNNConvolutionTranspose
.SH SYNOPSIS
.br
.PP
.PP
\fC#import <MPSCNNConvolution\&.h>\fP
.PP
Inherits \fBMPSCNNKernel\fP\&.
.SS "Instance Methods"

.in +1c
.ti -1c
.RI "(nonnull instancetype) \- \fBinitWithDevice:weights:\fP"
.br
.ti -1c
.RI "(nonnull instancetype) \- \fBinitWithDevice:\fP"
.br
.ti -1c
.RI "(nullable instancetype) \- \fBinitWithCoder:device:\fP"
.br
.ti -1c
.RI "(\fBMPSImage\fP *__nonnull) \- \fBencodeToCommandBuffer:sourceImage:convolutionGradientState:\fP"
.br
.ti -1c
.RI "(\fBMPSImageBatch\fP *__nonnull) \- \fBencodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:\fP"
.br
.ti -1c
.RI "(void) \- \fBencodeToCommandBuffer:sourceImage:convolutionGradientState:destinationImage:\fP"
.br
.ti -1c
.RI "(void) \- \fBencodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationImages:\fP"
.br
.in -1c
.SS "Properties"

.in +1c
.ti -1c
.RI "NSUInteger \fBinputFeatureChannels\fP"
.br
.ti -1c
.RI "NSUInteger \fBoutputFeatureChannels\fP"
.br
.ti -1c
.RI "NSInteger \fBkernelOffsetX\fP"
.br
.ti -1c
.RI "NSInteger \fBkernelOffsetY\fP"
.br
.ti -1c
.RI "NSUInteger \fBgroups\fP"
.br
.ti -1c
.RI "\fBMPSNNConvolutionAccumulatorPrecisionOption\fP \fBaccumulatorPrecisionOption\fP"
.br
.in -1c
.SS "Additional Inherited Members"
.SH "Detailed Description"
.PP 
This depends on Metal\&.framework  The \fBMPSCNNConvolutionTranspose\fP specifies a transposed convolution\&. The \fBMPSCNNConvolutionTranspose\fP convolves the input image with a set of filters, each producing one feature map in the output image\&.
.PP
Some third-party frameworks may rotate the weights spatially by 180 degrees for Convolution Transpose\&. MPS uses the weights specified by the developer as-is and does not perform any rotation\&. The developer may need to rotate the weights appropriately in case this rotation is needed before the convolution transpose is applied\&.
.PP
When the stride in any dimension is greater than 1, the convolution transpose puts (stride - 1) zeroes in-between the source image pixels to create an expanded image\&. Then a convolution is done over the expanded image to generate the output of the convolution transpose\&.
.PP
Intermediate image size = (srcSize - 1) * Stride + 1
.PP
Examples:
.PP
.PP
.nf
So in case of sride == 2 (this behaves same in both dimensions)

Source image:
 _______________
|   |   |   |   |
| 1 | 2 | 3 | 4 |
|   |   |   |   |
 ---------------

Intermediate Image:
 ___________________________
|   |   |   |   |   |   |   |
| 1 | 0 | 2 | 0 | 3 | 0 | 4 |
|   |   |   |   |   |   |   |
 ---------------------------


NOTE on Offset:
There are 2 types of offsets defined:
1) The Offset defined in MPSCNNKernel from which MPSCNNConvolutionTranspose inherits\&. This offset is applied to from where
   the kernel will be applied on the source\&.
2) The kernelOffsetX and kernelOffsetY which is the offset applied to the kernel when it is finally applied on the intermediate
   image\&.

So totalOffset = Offset * stride + kernelOffset

The offset defined by user refers to the coordinate frame of the expanded image
(we are showing only 1 dimension X it can be extended to Y dimension as well) :

X indicates where the convolution transpose begins:

Intermediate Image:  Offset = 0, kernelOffset = 0
 ___________________________
|   |   |   |   |   |   |   |
| 1 | 0 | 2 | 0 | 3 | 0 | 4 |
| X |   |   |   |   |   |   |
 ---------------------------


X indicates where the convolution transpose begins:

Intermediate Image:  Offset = 0, kernelOffset = 1
 ___________________________
|   |   |   |   |   |   |   |
| 1 | 0 | 2 | 0 | 3 | 0 | 4 |
|   | X |   |   |   |   |   |
 ---------------------------


X indicates where the convolution transpose begins:

Intermediate Image:  Offset = 0, kernelOffset = -1
   ___________________________
  |   |   |   |   |   |   |   |
X | 1 | 0 | 2 | 0 | 3 | 0 | 4 |
  |   |   |   |   |   |   |   |
   ---------------------------




So if the user wanted to apply an offset of 2 on the source image of convolution transpose:

Source image:
 _______________
|   |   |   |   |
| 1 | 2 | 3 | 4 |
|   |   | X |   |
 ---------------

offset = 2, kernelOffset = 0

Intermediate Image:
 ___________________________
|   |   |   |   |   |   |   |
| 1 | 0 | 2 | 0 | 3 | 0 | 4 |
|   |   |   |   | X |   |   |
 ---------------------------
.fi
.PP
 
.SH "Method Documentation"
.PP 
.SS "\- (\fBMPSImageBatch\fP * __nonnull) encodeBatchToCommandBuffer: (nonnull id< MTLCommandBuffer >) commandBuffer(\fBMPSImageBatch\fP *__nonnull) sourceImage(\fBMPSCNNConvolutionGradientStateBatch\fP *__nullable) convolutionGradientState"

.SS "\- (void) encodeBatchToCommandBuffer: (nonnull id< MTLCommandBuffer >) commandBuffer(\fBMPSImageBatch\fP *__nonnull) sourceImage(\fBMPSCNNConvolutionGradientStateBatch\fP *__nullable) convolutionGradientState(\fBMPSImageBatch\fP *__nonnull) destinationImage"

.SS "\- (\fBMPSImage\fP * __nonnull) encodeToCommandBuffer: (nonnull id< MTLCommandBuffer >) commandBuffer(\fBMPSImage\fP *__nonnull) sourceImage(\fBMPSCNNConvolutionGradientState\fP *__nullable) convolutionGradientState"
Encode a \fBMPSCNNKernel\fP into a command Buffer\&. Create a texture to hold the result and return it\&.  In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationImage: some work was left for the developer to do in the form of correctly setting the offset property and sizing the result buffer\&. With the introduction of the padding policy (see padding property) the filter can do this work itself\&. If you would like to have some input into what sort of \fBMPSImage\fP (e\&.g\&. temporary vs\&. regular) or what size it is or where it is allocated, you may set the destinationImageAllocator to allocate the image yourself\&.
.PP
This method uses the \fBMPSNNPadding\fP padding property to figure out how to size the result image and to set the offset property\&. See discussion in \fBMPSNeuralNetworkTypes\&.h\fP\&.
.PP
Note: the regular encodeToCommandBuffer:sourceImage: method may be used when no state is needed, such as when the convolution transpose operation is not balanced by a matching convolution object upstream\&.
.PP
\fBParameters:\fP
.RS 4
\fIcommandBuffer\fP The command buffer 
.br
\fIsourceImage\fP \fBA\fP \fBMPSImage\fP to use as the source images for the filter\&. 
.br
\fIconvolutionGradientState\fP \fBA\fP valid \fBMPSCNNConvolutionGradientState\fP from the MPSCNNConvoluton counterpart to this \fBMPSCNNConvolutionTranspose\fP\&. If there is no forward convolution counterpart, pass NULL here\&. This state affects the sizing the result\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
\fBA\fP \fBMPSImage\fP or \fBMPSTemporaryImage\fP allocated per the destinationImageAllocator containing the output of the graph\&. The offset property will be adjusted to reflect the offset used during the encode\&. The returned image will be automatically released when the command buffer completes\&. If you want to keep it around for longer, retain the image\&. (ARC will do this for you if you use it later\&.) 
.RE
.PP

.SS "\- (void) encodeToCommandBuffer: (nonnull id< MTLCommandBuffer >) commandBuffer(\fBMPSImage\fP *__nonnull) sourceImage(\fBMPSCNNConvolutionGradientState\fP *__nullable) convolutionGradientState(\fBMPSImage\fP *__nonnull) destinationImage"

.SS "\- (nullable instancetype) \fBinitWithCoder:\fP (NSCoder *__nonnull) aDecoder(nonnull id< MTLDevice >) device"
<NSSecureCoding> support 
.PP
Reimplemented from \fBMPSCNNKernel\fP\&.
.SS "\- (nonnull instancetype) initWithDevice: (nonnull id< MTLDevice >) device"
Standard init with default properties per filter type 
.PP
\fBParameters:\fP
.RS 4
\fIdevice\fP The device that the filter will be used on\&. May not be NULL\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
\fBA\fP pointer to the newly initialized object\&. This will fail, returning nil if the device is not supported\&. Devices must be MTLFeatureSet_iOS_GPUFamily2_v1 or later\&. 
.RE
.PP

.PP
Reimplemented from \fBMPSCNNKernel\fP\&.
.SS "\- (nonnull instancetype) \fBinitWithDevice:\fP (nonnull id< MTLDevice >) device(nonnull id< \fBMPSCNNConvolutionDataSource\fP >) weights"
Initializes a convolution transpose kernel 
.PP
\fBParameters:\fP
.RS 4
\fIdevice\fP The MTLDevice on which this \fBMPSCNNConvolutionTranspose\fP filter will be used 
.br
\fIweights\fP \fBA\fP pointer to a object that conforms to the \fBMPSCNNConvolutionDataSource\fP protocol\&. The \fBMPSCNNConvolutionDataSource\fP protocol declares the methods that an instance of \fBMPSCNNConvolutionTranspose\fP uses to obtain the weights and bias terms for the CNN convolutionTranspose filter\&. Currently we support only Float32 weights\&.
.RE
.PP
\fBReturns:\fP
.RS 4
\fBA\fP valid \fBMPSCNNConvolutionTranspose\fP object\&. 
.RE
.PP

.SH "Property Documentation"
.PP 
.SS "\- (\fBMPSNNConvolutionAccumulatorPrecisionOption\fP) accumulatorPrecisionOption\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
Precision of accumulator used in convolution\&.  See \fBMPSNeuralNetworkTypes\&.h\fP for discussion\&. Default is MPSNNConvolutionAccumulatorPrecisionOptionFloat\&. 
.SS "\- groups\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
Number of groups input and output channels are divided into\&. 
.SS "\- inputFeatureChannels\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The number of feature channels per pixel in the input image\&. 
.SS "\- kernelOffsetX\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
Offset in X from which the kernel starts sliding 
.SS "\- kernelOffsetY\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
Offset in Y from which the kernel starts sliding 
.SS "\- outputFeatureChannels\fC [read]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The number of feature channels per pixel in the output image\&. 

.SH "Author"
.PP 
Generated automatically by Doxygen for MetalPerformanceShaders\&.framework from the source code\&.
