.TH "MPSNNNeuronDescriptor" 3 "Mon Jul 9 2018" "Version MetalPerformanceShaders-119.3" "MetalPerformanceShaders.framework" \" -*- nroff -*-
.ad l
.nh
.SH NAME
MPSNNNeuronDescriptor
.SH SYNOPSIS
.br
.PP
.PP
\fC#import <MPSCNNNeuron\&.h>\fP
.PP
Inherits NSObject, and <NSCopying>\&.
.SS "Instance Methods"

.in +1c
.ti -1c
.RI "(nonnull instancetype) \- \fBinit\fP"
.br
.in -1c
.SS "Class Methods"

.in +1c
.ti -1c
.RI "(nonnull \fBMPSNNNeuronDescriptor\fP *) + \fBcnnNeuronDescriptorWithType:\fP"
.br
.ti -1c
.RI "(nonnull \fBMPSNNNeuronDescriptor\fP *) + \fBcnnNeuronDescriptorWithType:a:\fP"
.br
.ti -1c
.RI "(nonnull \fBMPSNNNeuronDescriptor\fP *) + \fBcnnNeuronDescriptorWithType:a:b:\fP"
.br
.ti -1c
.RI "(nonnull \fBMPSNNNeuronDescriptor\fP *) + \fBcnnNeuronDescriptorWithType:a:b:c:\fP"
.br
.ti -1c
.RI "(nonnull \fBMPSNNNeuronDescriptor\fP *) + \fBcnnNeuronPReLUDescriptorWithData:noCopy:\fP"
.br
.in -1c
.SS "Properties"

.in +1c
.ti -1c
.RI "\fBMPSCNNNeuronType\fP \fBneuronType\fP"
.br
.ti -1c
.RI "float \fBa\fP"
.br
.ti -1c
.RI "float \fBb\fP"
.br
.ti -1c
.RI "float \fBc\fP"
.br
.ti -1c
.RI "NSData * \fBdata\fP"
.br
.in -1c
.SH "Detailed Description"
.PP 
This depends on Metal\&.framework  The \fBMPSNNNeuronDescriptor\fP specifies a neuron descriptor\&. Supported neuron types:
.PP
Neuron type 'none': f(x) = x Parameters: none
.PP
ReLU neuron filter: f(x) = x >= 0 ? x : a * x This is called Leaky ReLU in literature\&. Some literature defines classical ReLU as max(0, x)\&. If you want this behavior, simply pass a = 0\&. Parameters: a For default behavior, set the value of a to 0\&.0f\&.
.PP
Linear neuron filter: f(x) = a * x + b Parameters: a, b For default behavior, set the value of a to 1\&.0f and the value of b to 0\&.0f\&.
.PP
Sigmoid neuron filter: f(x) = 1 / (1 + e^-x) Parameters: none
.PP
Hard Sigmoid filter: f(x) = clamp((x * a) + b, 0, 1) Parameters: a, b For default behavior, set the value of a to 0\&.2f and the value of b to 0\&.5f\&.
.PP
Hyperbolic tangent (TanH) neuron filter: f(x) = a * tanh(b * x) Parameters: a, b For default behavior, set the value of a to 1\&.0f and the value of b to 1\&.0f\&.
.PP
Absolute neuron filter: f(x) = fabs(x) Parameters: none
.PP
Parametric Soft Plus neuron filter: f(x) = a * log(1 + e^(b * x)) Parameters: a, b For default behavior, set the value of a to 1\&.0f and the value of b to 1\&.0f\&.
.PP
Parametric Soft Sign neuron filter: f(x) = x / (1 + abs(x)) Parameters: none
.PP
Parametric ELU neuron filter: f(x) = x >= 0 ? x : a * (exp(x) - 1) Parameters: a For default behavior, set the value of a to 1\&.0f\&.
.PP
Parametric ReLU (PReLU) neuron filter: Same as ReLU, except parameter aArray is per channel\&. For each pixel, applies the following function: f(x_i) = x_i, if x_i >= 0 = a_i * x_i if x_i < 0 i in [0\&.\&.\&.channels-1] i\&.e\&. parameters a_i are learned and applied to each channel separately\&. Compare this to ReLu where parameter a is shared across all channels\&. See https://arxiv.org/pdf/1502.01852.pdf for details\&. Parameters: aArray - Array of floats containing per channel value of PReLu parameter count - Number of float values in array aArray\&.
.PP
ReLUN neuron filter: f(x) = min((x >= 0 ? x : a * x), b) Parameters: a, b As an example, the TensorFlow Relu6 activation layer can be implemented by setting the parameter b to 6\&.0f: https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/relu6\&. For default behavior, set the value of a to 1\&.0f and the value of b to 6\&.0f\&. 
.SH "Method Documentation"
.PP 
.SS "+ (nonnull \fBMPSNNNeuronDescriptor\fP*) cnnNeuronDescriptorWithType: (\fBMPSCNNNeuronType\fP) neuronType"
Make a descriptor for a \fBMPSCNNNeuron\fP object\&. 
.PP
\fBParameters:\fP
.RS 4
\fIneuronType\fP The type of a neuron filter\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
\fBA\fP valid \fBMPSNNNeuronDescriptor\fP object or nil, if failure\&. 
.RE
.PP

.SS "+ (nonnull \fBMPSNNNeuronDescriptor\fP*) \fBcnnNeuronDescriptorWithType:\fP (\fBMPSCNNNeuronType\fP) neuronType(float) a"
Make a descriptor for a \fBMPSCNNNeuron\fP object\&. 
.PP
\fBParameters:\fP
.RS 4
\fIneuronType\fP The type of a neuron filter\&. 
.br
\fIa\fP Parameter 'a'\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
\fBA\fP valid \fBMPSNNNeuronDescriptor\fP object or nil, if failure\&. 
.RE
.PP

.SS "+ (nonnull \fBMPSNNNeuronDescriptor\fP*) \fBcnnNeuronDescriptorWithType:\fP (\fBMPSCNNNeuronType\fP) neuronType(float) a(float) b"
Initialize the neuron descriptor\&. 
.PP
\fBParameters:\fP
.RS 4
\fIneuronType\fP The type of a neuron filter\&. 
.br
\fIa\fP Parameter 'a'\&. 
.br
\fIb\fP Parameter 'b'\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
\fBA\fP valid \fBMPSNNNeuronDescriptor\fP object or nil, if failure\&. 
.RE
.PP

.SS "+ (nonnull \fBMPSNNNeuronDescriptor\fP*) \fBcnnNeuronDescriptorWithType:\fP (\fBMPSCNNNeuronType\fP) neuronType(float) a(float) b(float) c"
Make a descriptor for a \fBMPSCNNNeuron\fP object\&. 
.PP
\fBParameters:\fP
.RS 4
\fIneuronType\fP The type of a neuron filter\&. 
.br
\fIa\fP Parameter 'a'\&. 
.br
\fIb\fP Parameter 'b'\&. 
.br
\fIc\fP Parameter 'c'\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
\fBA\fP valid \fBMPSNNNeuronDescriptor\fP object or nil, if failure\&. 
.RE
.PP

.SS "+ (nonnull \fBMPSNNNeuronDescriptor\fP*) cnnNeuronPReLUDescriptorWithData: (NSData *_Nonnull) data(bool) noCopy"
Make a descriptor for a neuron of type MPSCNNNeuronTypePReLU\&.  The PReLU neuron is the same as a ReLU neuron, except parameter 'a' is per feature channel\&. 
.PP
\fBParameters:\fP
.RS 4
\fIdata\fP \fBA\fP NSData containing a float array with the per feature channel value of PReLu parameter\&. The number of float values in this array usually corresponds to number of output channels in a convolution layer\&. The descriptor retains the NSData object\&. 
.br
\fInoCopy\fP An optimization flag that tells us whether the NSData allocation is suitable for use directly with no copying of the data into internal storage\&. This allocation has to match the same restrictions as listed for the newBufferWithBytesNoCopy:length:options:deallocator: method of MTLBuffer\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
\fBA\fP valid \fBMPSNNNeuronDescriptor\fP object for a neuron of type MPSCNNNeuronTypePReLU or nil, if failure 
.RE
.PP

.SS "\- (nonnull instancetype) init "
You must use one of the interfaces below instead\&. 
.SH "Property Documentation"
.PP 
.SS "\- (float) a\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"

.SS "\- (float) b\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"

.SS "\- (float) c\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"

.SS "\- (NSData*) data\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [retain]\fP"

.SS "\- (\fBMPSCNNNeuronType\fP) neuronType\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"


.SH "Author"
.PP 
Generated automatically by Doxygen for MetalPerformanceShaders\&.framework from the source code\&.
